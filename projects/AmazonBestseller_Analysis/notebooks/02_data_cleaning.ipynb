{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bestseller Analysis: Data Cleaning\n",
    "\n",
    "### Notebook 02: Python Data Cleaning\n",
    "\n",
    "This is the next notebook in the Amazon Bestseller Analysis project where I will clean and preprocess the bestseller data collected from Amazon. The main tasks are:\n",
    "    \n",
    "1. Load and combine data from today's scraper run\n",
    "2. Clean and standardise titles (remove formatting, handle series information)\n",
    "3. Handle missing format data\n",
    "4. Standardise categories and age ranges\n",
    "5. Create derived fields (price bands, age groups)\n",
    "6. Export cleaned data for analysis\n",
    "\n",
    "I have broken down the age ranges into distinct segments (6-8, 9-12, 12-14, 14-18) to allow for nuanced analysis of reading progression and format preferences as young readers mature, which I've found particularly valuable when considering series development and format strategies.\n",
    "\n",
    "To start, loading the necessary libraries and files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 20250119\n",
      "Loading raw data from: ../data/raw/daily_bestsellers/bestsellers_20250119.csv\n",
      "Loaded 239 records from today's scrape\n"
     ]
    }
   ],
   "source": [
    "today = datetime.now().strftime(\"%Y%m%d\")\n",
    "raw_file_path = f'../data/raw/daily_bestsellers/bestsellers_{today}.csv'\n",
    "master_file_path = '../data/processed/master_bestsellers.csv'\n",
    "\n",
    "print(f\"Processing data for {today}\")\n",
    "print(f\"Loading raw data from: {raw_file_path}\")\n",
    "\n",
    "# Load today's data\n",
    "df_today = pd.read_csv(raw_file_path)\n",
    "print(f\"Loaded {len(df_today)} records from today's scrape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want to check for any immediate issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239 entries, 0 to 238\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   rank              239 non-null    int64  \n",
      " 1   title             239 non-null    object \n",
      " 2   author            212 non-null    object \n",
      " 3   price             238 non-null    float64\n",
      " 4   format            239 non-null    object \n",
      " 5   rating            232 non-null    float64\n",
      " 6   review_count      232 non-null    float64\n",
      " 7   isbn10            181 non-null    object \n",
      " 8   isbn13            200 non-null    float64\n",
      " 9   page_count        217 non-null    float64\n",
      " 10  category          239 non-null    object \n",
      " 11  target_age_range  167 non-null    object \n",
      " 12  timestamp         239 non-null    object \n",
      " 13  asin              239 non-null    object \n",
      " 14  product_url       239 non-null    object \n",
      " 15  image_url         239 non-null    object \n",
      " 16  category_ranks    119 non-null    object \n",
      "dtypes: float64(5), int64(1), object(11)\n",
      "memory usage: 31.9+ KB\n",
      "None\n",
      "Missing Values:\n",
      "rank                  0\n",
      "title                 0\n",
      "author               27\n",
      "price                 1\n",
      "format                0\n",
      "rating                7\n",
      "review_count          7\n",
      "isbn10               58\n",
      "isbn13               39\n",
      "page_count           22\n",
      "category              0\n",
      "target_age_range     72\n",
      "timestamp             0\n",
      "asin                  0\n",
      "product_url           0\n",
      "image_url             0\n",
      "category_ranks      120\n",
      "dtype: int64\n",
      "Value Counts for Format:\n",
      "format\n",
      "Paperback            119\n",
      "Hardcover             42\n",
      "Board book            32\n",
      "Audible Audiobook     20\n",
      "Kindle Edition        18\n",
      "Spiral-bound           2\n",
      "Toy                    1\n",
      "Product Bundle         1\n",
      "Cards                  1\n",
      "Card Book              1\n",
      "Loose Leaf             1\n",
      "Pop-Up                 1\n",
      "Name: count, dtype: int64\n",
      "Value Counts for Category:\n",
      "category\n",
      "Classic Books                         30\n",
      "Sport and Outdoors                    30\n",
      "Teen and Young Adult                  30\n",
      "Comics and Graphic Novels             30\n",
      "Science, Nature & How It Works        30\n",
      "Educational Books                     30\n",
      "Reference Books                       30\n",
      "TV, Movie & Video Game Adaptations    29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "print(df_today.info())\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(df_today.isnull().sum())\n",
    "\n",
    "print(\"Value Counts for Format:\")\n",
    "print(df_today['format'].value_counts(dropna=False))\n",
    "\n",
    "print(\"Value Counts for Category:\")\n",
    "print(df_today['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Format of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer columns from float\n",
    "integer_columns = ['review_count', 'page_count', 'isbn13']\n",
    "for col in integer_columns:\n",
    "    df_today[col] = df_today[col].fillna(0)\n",
    "    df_today[col] = df_today[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardise date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age Range Distribution:\n",
      "age_range_std\n",
      "NaN      68\n",
      "9-12     46\n",
      "3-5      41\n",
      "6-8      37\n",
      "15-18    30\n",
      "0-2      17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def extract_age_range(age_str):\n",
    "    \"\"\"Extract age range from string formats like '1-2', '7+', etc.\"\"\"\n",
    "    if pd.isna(age_str):\n",
    "        return None, None\n",
    "    \n",
    "    age_str = str(age_str).lower().strip()\n",
    "    \n",
    "    # Handle '+' format (e.g., '7+')\n",
    "    if '+' in age_str:\n",
    "        start_age = int(''.join(filter(str.isdigit, age_str)))\n",
    "        return start_age, None\n",
    "    \n",
    "    # Handle range format (e.g., '1-2', '7 to 9')\n",
    "    numbers = [int(n) for n in ''.join(c if c.isdigit() else ' ' for c in age_str).split()]\n",
    "    if len(numbers) >= 2:\n",
    "        return numbers[0], numbers[1]\n",
    "    elif len(numbers) == 1:\n",
    "        return numbers[0], None\n",
    "        \n",
    "    return None, None\n",
    "\n",
    "def map_to_standard_range(start_age, end_age):\n",
    "    \"\"\"Map extracted ages to standard publishing ranges\"\"\"\n",
    "    standard_ranges = [\n",
    "        (0, 2, '0-2'),\n",
    "        (3, 5, '3-5'),\n",
    "        (6, 8, '6-8'),\n",
    "        (9, 12, '9-12'),\n",
    "        (13, 14, '13-14'),\n",
    "        (15, 18, '15-18')\n",
    "    ]\n",
    "    \n",
    "    if start_age is None:\n",
    "        return None\n",
    "        \n",
    "    # Handle '+' format\n",
    "    if end_age is None:\n",
    "        if start_age <= 2:\n",
    "            return '0-2'\n",
    "        elif start_age <= 5:\n",
    "            return '3-5'\n",
    "        elif start_age <= 8:\n",
    "            return '6-8'\n",
    "        elif start_age <= 12:\n",
    "            return '9-12'\n",
    "        elif start_age <= 14:\n",
    "            return '13-14'\n",
    "        else:\n",
    "            return '15-18'\n",
    "            \n",
    "    # Handle range format\n",
    "    avg_age = (start_age + end_age) / 2\n",
    "    for low, high, range_str in standard_ranges:\n",
    "        if low <= avg_age <= high:\n",
    "            return range_str\n",
    "            \n",
    "    # Default to closest range\n",
    "    if avg_age < 0:\n",
    "        return '0-2'\n",
    "    elif avg_age > 18:\n",
    "        return '15-18'\n",
    "    \n",
    "    return None\n",
    "\n",
    "def standardise_age_range(row):\n",
    "    \"\"\"Create standardised age ranges based on target_age_range or category\"\"\"\n",
    "    # First try to use target_age_range\n",
    "    if pd.notna(row['target_age_range']):\n",
    "        start_age, end_age = extract_age_range(row['target_age_range'])\n",
    "        if start_age is not None:\n",
    "            std_range = map_to_standard_range(start_age, end_age)\n",
    "            if std_range:\n",
    "                return std_range\n",
    "    \n",
    "    # If no valid age range found, use category\n",
    "    category = str(row['category']).lower()\n",
    "    category_mappings = {\n",
    "        'baby': '0-2',\n",
    "        'toddler': '0-2',\n",
    "        'preschool': '3-5',\n",
    "        'kindergarten': '3-5',\n",
    "        'early reader': '6-8',\n",
    "        'ages 6-8': '6-8',\n",
    "        'middle grade': '9-12',\n",
    "        'ages 9-12': '9-12',\n",
    "        'young teen': '13-14',\n",
    "        'ages 12-14': '13-14',\n",
    "        'teen': '15-18',\n",
    "        'young adult': '15-18',\n",
    "        'ages 14-18': '15-18'\n",
    "    }\n",
    "    \n",
    "    for key, value in category_mappings.items():\n",
    "        if key in category:\n",
    "            return value\n",
    "            \n",
    "    return None\n",
    "\n",
    "# Apply age range standardization\n",
    "df_today['age_range_std'] = df_today.apply(standardise_age_range, axis=1)\n",
    "\n",
    "# Create age group categories\n",
    "age_group_mapping = {\n",
    "    '0-2': '0-2',\n",
    "    '3-5': '3-5',\n",
    "    '6-8': '6-8',\n",
    "    '9-12': '9-12',\n",
    "    '13-14': '13-14',\n",
    "    '15-18': '15-18'\n",
    "}\n",
    "df_today['age_range_std'] = df_today['age_range_std'].map(age_group_mapping)\n",
    "#df_today = df_today.drop(['target_age_range','target_age_group'], axis =1)\n",
    "# Print age range distribution\n",
    "print(\"\\nAge Range Distribution:\")\n",
    "print(df_today['age_range_std'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the category columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename basic ranking columns for clarity\n",
    "df_today = df_today.rename(columns={\n",
    "    'rank': 'main_category_rank',\n",
    "    'category': 'main_category'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_category_ranking(category_str):\n",
    "    \"\"\"Parse category ranking string into separate categories and ranks\"\"\"\n",
    "    if pd.isna(category_str):\n",
    "        return pd.Series({\n",
    "            'category_1': None, \n",
    "            'category_1_rank': pd.NA,\n",
    "            'category_2': None, \n",
    "            'category_2_rank': pd.NA,\n",
    "            'category_3': None, \n",
    "            'category_3_rank': pd.NA\n",
    "        })\n",
    "        \n",
    "    # Split into individual category-rank pairs\n",
    "    categories = [x.strip() for x in str(category_str).split('|')]\n",
    "    \n",
    "    # Initialise results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    # Process up to 3 categories\n",
    "    for i in range(3):\n",
    "        # Set default values\n",
    "        results[f'category_{i+1}'] = None\n",
    "        results[f'category_{i+1}_rank'] = pd.NA\n",
    "        \n",
    "        # If data for this position, process it\n",
    "        if i < len(categories):\n",
    "            cat_data = categories[i].strip()\n",
    "            \n",
    "            # Extract rank (first number in string)\n",
    "            rank_match = re.match(r'(\\d+)', cat_data)\n",
    "            if rank_match:\n",
    "                results[f'category_{i+1}_rank'] = pd.NA if rank_match is None else int(rank_match.group(1))\n",
    "                \n",
    "                # Extract category (everything after 'in ')\n",
    "                category = re.search(r' in (.+)', cat_data)\n",
    "                if category:\n",
    "                    results[f'category_{i+1}'] = category.group(1).strip()\n",
    "    \n",
    "    # Convert to series with proper types\n",
    "    series = pd.Series(results)\n",
    "    for i in range(1, 4):\n",
    "        if pd.notna(series[f'category_{i}_rank']):\n",
    "            series[f'category_{i}_rank'] = int(series[f'category_{i}_rank'])\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the parsing function and add new columns\n",
    "df_today = df_today.rename(columns={'rank': 'main_category_rank', 'category': 'main_category'})\n",
    "parsed_categories = df_today['category_ranks'].apply(parse_category_ranking)\n",
    "df_today = pd.concat([df_today, parsed_categories], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category_rank</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price</th>\n",
       "      <th>format</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>page_count</th>\n",
       "      <th>...</th>\n",
       "      <th>product_url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>category_ranks</th>\n",
       "      <th>age_range_std</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_1_rank</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_2_rank</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_3_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Guess How Much I Love You: The beloved classic...</td>\n",
       "      <td>Sam McBratney</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Board book</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9781406358780</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.co.uk/Guess-How-Much-Love-Y...</td>\n",
       "      <td>https://images-eu.ssl-images-amazon.com/images...</td>\n",
       "      <td>1 in Fiction About Emotions &amp; Feelings for Chi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fiction About Emotions &amp; Feelings for Children</td>\n",
       "      <td>1</td>\n",
       "      <td>Classics for Children</td>\n",
       "      <td>1</td>\n",
       "      <td>Children's Books on Valentine's Day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dear Zoo: The Lift-the-flap Preschool Classic</td>\n",
       "      <td>Rod Campbell</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Board book</td>\n",
       "      <td>4.8</td>\n",
       "      <td>30581</td>\n",
       "      <td>1529074932</td>\n",
       "      <td>9781529074932</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.co.uk/Dear-Zoo-Anniversary-...</td>\n",
       "      <td>https://images-eu.ssl-images-amazon.com/images...</td>\n",
       "      <td>2 in Classics for Children | 2 in Children's E...</td>\n",
       "      <td>0-2</td>\n",
       "      <td>Classics for Children</td>\n",
       "      <td>2</td>\n",
       "      <td>Children's Early Learning Books on Size &amp; Shape</td>\n",
       "      <td>2</td>\n",
       "      <td>Children's Fiction Books on Animals</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Tiger Who Came to Tea</td>\n",
       "      <td>Judith Kerr</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.8</td>\n",
       "      <td>15641</td>\n",
       "      <td>0007368380</td>\n",
       "      <td>9780007215997</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.co.uk/Tiger-Who-Came-Tea/dp...</td>\n",
       "      <td>https://images-eu.ssl-images-amazon.com/images...</td>\n",
       "      <td>2 in Children’s Daily Activity Fiction Books |...</td>\n",
       "      <td>3-5</td>\n",
       "      <td>Children’s Daily Activity Fiction Books</td>\n",
       "      <td>2</td>\n",
       "      <td>Classics for Children</td>\n",
       "      <td>3</td>\n",
       "      <td>Doctors &amp; Medicine Humour</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We're Going on a Bear Hunt: The bestselling cl...</td>\n",
       "      <td>Michael Rosen</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4779</td>\n",
       "      <td>0744523230</td>\n",
       "      <td>9780744523232</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.co.uk/Were-Going-Bear-Micha...</td>\n",
       "      <td>https://images-eu.ssl-images-amazon.com/images...</td>\n",
       "      <td>2 in Children's Early Learning Books on Words ...</td>\n",
       "      <td>3-5</td>\n",
       "      <td>Children's Early Learning Books on Words</td>\n",
       "      <td>2</td>\n",
       "      <td>Classics for Children</td>\n",
       "      <td>4</td>\n",
       "      <td>Activity Books for Children</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Oh Dear!: A Lift-the-flap Farm Book from the C...</td>\n",
       "      <td>Rod Campbell</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Board book</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2619</td>\n",
       "      <td>1529097886</td>\n",
       "      <td>9781529097887</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.co.uk/Oh-Dear-Rod-Campbell/...</td>\n",
       "      <td>https://images-eu.ssl-images-amazon.com/images...</td>\n",
       "      <td>1 in Children's Books on Easter | 2 in Childre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Children's Books on Easter</td>\n",
       "      <td>1</td>\n",
       "      <td>Children's Books on Country &amp; Farm Life</td>\n",
       "      <td>2</td>\n",
       "      <td>Children's Books on Farm Animals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   main_category_rank                                              title  \\\n",
       "0                   1  Guess How Much I Love You: The beloved classic...   \n",
       "1                   2      Dear Zoo: The Lift-the-flap Preschool Classic   \n",
       "2                   3                          The Tiger Who Came to Tea   \n",
       "3                   4  We're Going on a Bear Hunt: The bestselling cl...   \n",
       "4                   5  Oh Dear!: A Lift-the-flap Farm Book from the C...   \n",
       "\n",
       "          author  price      format  rating  review_count      isbn10  \\\n",
       "0  Sam McBratney    4.0  Board book     4.8          8752         NaN   \n",
       "1   Rod Campbell    4.0  Board book     4.8         30581  1529074932   \n",
       "2    Judith Kerr    4.0   Paperback     4.8         15641  0007368380   \n",
       "3  Michael Rosen    4.0   Paperback     4.8          4779  0744523230   \n",
       "4   Rod Campbell    4.0  Board book     4.8          2619  1529097886   \n",
       "\n",
       "          isbn13  page_count  ...  \\\n",
       "0  9781406358780          32  ...   \n",
       "1  9781529074932          18  ...   \n",
       "2  9780007215997          32  ...   \n",
       "3  9780744523232          40  ...   \n",
       "4  9781529097887          18  ...   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  https://www.amazon.co.uk/Guess-How-Much-Love-Y...   \n",
       "1  https://www.amazon.co.uk/Dear-Zoo-Anniversary-...   \n",
       "2  https://www.amazon.co.uk/Tiger-Who-Came-Tea/dp...   \n",
       "3  https://www.amazon.co.uk/Were-Going-Bear-Micha...   \n",
       "4  https://www.amazon.co.uk/Oh-Dear-Rod-Campbell/...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images-eu.ssl-images-amazon.com/images...   \n",
       "1  https://images-eu.ssl-images-amazon.com/images...   \n",
       "2  https://images-eu.ssl-images-amazon.com/images...   \n",
       "3  https://images-eu.ssl-images-amazon.com/images...   \n",
       "4  https://images-eu.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                      category_ranks age_range_std  \\\n",
       "0  1 in Fiction About Emotions & Feelings for Chi...           NaN   \n",
       "1  2 in Classics for Children | 2 in Children's E...           0-2   \n",
       "2  2 in Children’s Daily Activity Fiction Books |...           3-5   \n",
       "3  2 in Children's Early Learning Books on Words ...           3-5   \n",
       "4  1 in Children's Books on Easter | 2 in Childre...           NaN   \n",
       "\n",
       "                                       category_1 category_1_rank  \\\n",
       "0  Fiction About Emotions & Feelings for Children               1   \n",
       "1                           Classics for Children               2   \n",
       "2         Children’s Daily Activity Fiction Books               2   \n",
       "3        Children's Early Learning Books on Words               2   \n",
       "4                      Children's Books on Easter               1   \n",
       "\n",
       "                                        category_2 category_2_rank  \\\n",
       "0                            Classics for Children               1   \n",
       "1  Children's Early Learning Books on Size & Shape               2   \n",
       "2                            Classics for Children               3   \n",
       "3                            Classics for Children               4   \n",
       "4          Children's Books on Country & Farm Life               2   \n",
       "\n",
       "                            category_3 category_3_rank  \n",
       "0  Children's Books on Valentine's Day               1  \n",
       "1  Children's Fiction Books on Animals               6  \n",
       "2            Doctors & Medicine Humour               4  \n",
       "3          Activity Books for Children              12  \n",
       "4     Children's Books on Farm Animals               2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_today.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and standardise text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean titles\n",
    "df_today['clean_title'] = df_today['title'].str.strip()\n",
    "df_today['clean_title'] = df_today['clean_title'].str.replace('\"', '\"').str.replace('\"', '\"')\n",
    "\n",
    "# Clean author names\n",
    "df_today['author'] = df_today['author'].str.strip()\n",
    "df_today['author'] = df_today['author'].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Format standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_mapping = {\n",
    "    'paperback': 'Paperback',\n",
    "    'hardcover': 'Hardcover',\n",
    "    'hard cover': 'Hardcover',\n",
    "    'board book': 'Board Book',\n",
    "    'board': 'Board Book',\n",
    "    'kindle': 'Digital',\n",
    "    'ebook': 'Digital',\n",
    "    'e-book': 'Digital',\n",
    "    'audiobook': 'Audio',\n",
    "    'audio book': 'Audio'\n",
    "}\n",
    "\n",
    "df_today['standardised_format'] = df_today['format'].str.lower().map(format_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Add processing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_today['processing_date'] = today\n",
    "df_today['data_batch'] = f'batch_{today}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. Validation checks before appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_issues = []\n",
    "\n",
    "# Check for critical issues\n",
    "if len(df_today) == 0:\n",
    "    validation_issues.append(\"No records found in today's data\")\n",
    "    \n",
    "if df_today['price'].isnull().all():\n",
    "    validation_issues.append(\"All prices are missing\")\n",
    "    \n",
    "if df_today['standardised_format'].isnull().all():\n",
    "    validation_issues.append(\"All formats are missing\")\n",
    "\n",
    "# Check for suspicious patterns\n",
    "    \n",
    "if df_today['price'].max() > 100:\n",
    "    validation_issues.append(f\"Suspicious high price found: {df_today['price'].max()}\")\n",
    "\n",
    "if len(validation_issues) > 0:\n",
    "    print(\"\\nWARNING: Data validation issues found:\")\n",
    "    for issue in validation_issues:\n",
    "        print(f\"- {issue}\")\n",
    "    print(\"\\nPlease review the issues before proceeding.\")\n",
    "else:\n",
    "    print(\"Data validation passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8. Load and append to master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 239 existing records from master dataset\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(master_file_path):\n",
    "    # Load existing master data\n",
    "    df_master = pd.read_csv(master_file_path)\n",
    "    print(f\"Loaded {len(df_master)} existing records from master dataset\")\n",
    "    \n",
    "    # Append new data\n",
    "    df_master = pd.concat([df_master, df_today], ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates based on business key (adjust columns as needed)\n",
    "    df_master = df_master.drop_duplicates(\n",
    "        subset=['clean_title', 'author', 'standardised_format', 'processing_date'],\n",
    "        keep='last'\n",
    "    )\n",
    "else:\n",
    "    print(\"No existing master dataset found. Creating new one.\")\n",
    "    df_master = df_today\n",
    "\n",
    "# Save updated master dataset\n",
    "df_master.to_csv(master_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Generate daily summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daily Processing Summary:\n",
      "--------------------------------------------------\n",
      "Date: 20250119\n",
      "Records processed: 239\n",
      "Records in master dataset: 433\n",
      "\n",
      "Format Distribution (Today):\n",
      "standardised_format\n",
      "Paperback     119\n",
      "Hardcover      42\n",
      "Board Book     32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Price Statistics (Today):\n",
      "count    238.000000\n",
      "mean       7.152353\n",
      "std        5.456755\n",
      "min        0.990000\n",
      "25%        4.000000\n",
      "50%        5.985000\n",
      "75%        7.925000\n",
      "max       39.990000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Processing complete. Check processing_log.csv for historical records.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDaily Processing Summary:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Date: {today}\")\n",
    "print(f\"Records processed: {len(df_today)}\")\n",
    "print(f\"Records in master dataset: {len(df_master)}\")\n",
    "print(\"\\nFormat Distribution (Today):\")\n",
    "print(df_today['standardised_format'].value_counts())\n",
    "print(\"\\nPrice Statistics (Today):\")\n",
    "print(df_today['price'].describe())\n",
    "\n",
    "# 10. Save daily summary to log\n",
    "log_file_path = '../data/processed/processing_log.csv'\n",
    "daily_summary = {\n",
    "    'date': today,\n",
    "    'records_processed': len(df_today),\n",
    "    'total_records': len(df_master),\n",
    "    'validation_issues': '; '.join(validation_issues) if validation_issues else 'None'\n",
    "}\n",
    "\n",
    "if os.path.exists(log_file_path):\n",
    "    df_log = pd.read_csv(log_file_path)\n",
    "else:\n",
    "    df_log = pd.DataFrame(columns=['date', 'records_processed', 'total_records', 'validation_issues'])\n",
    "\n",
    "df_log = pd.concat([df_log, pd.DataFrame([daily_summary])], ignore_index=True)\n",
    "df_log.to_csv(log_file_path, index=False)\n",
    "\n",
    "print(\"\\nProcessing complete. Check processing_log.csv for historical records.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Next Steps\n",
    "\n",
    "## Data Cleaning Accomplished\n",
    "In this notebook, I worked on comprehensive data preparation and cleaning. I began by standardising and cleaning book titles and extracting series information before handling missing format data through inference. To ensure consistency, I standardised categories and age ranges. The process included implementing data quality checks and saving reusable cleaning functions. \n",
    "\n",
    "Now, the resulting dataset has complete data for essential fields like title, author, price and format, with standardised formats and categories and normalised rankings within categories. I also created consistent age groupings across the data. Key improvements included filling missing format data using title and price inference, standardising age ranges across categories, adding normalised ranking metrics and extracting standardised series information. \n",
    "\n",
    "### Next Steps:\n",
    "3. Price analysis ([03_price_analysis.ipynb](03_price_analysis.ipynb)): Create visualizations of price distributions across formats and categories\n",
    "4. Genre analysis ([04_genre_analysis.ipynb](04_genre_analysis.ipynb)): Analyze category performance and age-range segmentation\n",
    "5. Seasonal analysis ([05_seasonal_analysis.ipynb](05_seasonal_analysis)): Begin tracking temporal patterns (will become more valuable as I collect more data over time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
