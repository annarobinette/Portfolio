{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bestseller Analysis: Genre Analysis\n",
    "\n",
    "### Notebook 04: Genre/Category Analysis\n",
    "\n",
    "This is the first notebook in the Amazon Bestseller Analysis project where I will focus on the initial data collection phase and gather bestseller data from Amazon's website in an ethical and structured manner.\n",
    "\n",
    "In this notebook I will:\n",
    "1. Set up the scraping infrastructure\n",
    "2. Collect bestseller data across multiple categories\n",
    "3. Store the data in a structured format for further analysis\n",
    "\n",
    "I will begin by importing the required libraries and setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Export Summary ===\n",
      "            dataset  record_count export_date\n",
      "main_category_stats             8    20250118\n",
      "  subcategory_stats           217    20250118\n",
      "format_distribution            29    20250118\n",
      " category_crossover           467    20250118\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_main_category_data(df):\n",
    "    \"\"\"\n",
    "    Prepare main category performance data for PowerBI\n",
    "    Tracks daily performance metrics for main categories\n",
    "    \"\"\"\n",
    "    main_category_stats = df.groupby(['processing_date', 'main_category']).agg({\n",
    "        'isbn13': 'count',  # Number of books in category\n",
    "        'main_category_rank': ['min', 'max', 'mean'],  # Rank statistics\n",
    "        'price': ['mean', 'median'],\n",
    "        'rating': ['mean', 'min', 'max'],\n",
    "        'review_count': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    main_category_stats.columns = [\n",
    "        f'{x[0]}_{x[1]}' if x[1] != '' else x[0]\n",
    "        for x in main_category_stats.columns\n",
    "    ]\n",
    "    \n",
    "    return main_category_stats.reset_index()\n",
    "\n",
    "def prepare_subcategory_data(df):\n",
    "    \"\"\"\n",
    "    Prepare subcategory analysis for PowerBI\n",
    "    Handles all three category levels\n",
    "    \"\"\"\n",
    "    # Process each category level\n",
    "    category_levels = []\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        category_col = f'category_{i}'\n",
    "        rank_col = f'category_{i}_rank'\n",
    "        \n",
    "        if category_col in df.columns and rank_col in df.columns:\n",
    "            level_stats = df.groupby(['processing_date', category_col]).agg({\n",
    "                'isbn13': 'count',\n",
    "                rank_col: ['min', 'max', 'mean'],\n",
    "                'price': ['mean', 'median'],\n",
    "                'rating': 'mean',\n",
    "                'review_count': 'sum'\n",
    "            }).round(2)\n",
    "            \n",
    "            # Flatten column names and add category level\n",
    "            level_stats.columns = [\n",
    "                f'{x[0]}_{x[1]}' if x[1] != '' else x[0]\n",
    "                for x in level_stats.columns\n",
    "            ]\n",
    "            \n",
    "            level_data = level_stats.reset_index()\n",
    "            level_data['category_level'] = i\n",
    "            level_data = level_data.rename(columns={category_col: 'category_name'})\n",
    "            \n",
    "            category_levels.append(level_data)\n",
    "    \n",
    "    # Combine all category levels\n",
    "    if category_levels:\n",
    "        return pd.concat(category_levels, ignore_index=True)\n",
    "    return pd.DataFrame()  # Return empty DataFrame if no category data\n",
    "\n",
    "def prepare_category_format_analysis(df):\n",
    "    \"\"\"\n",
    "    Analyze format distribution within categories\n",
    "    Uses the standardized format groupings\n",
    "    \"\"\"\n",
    "    # Define standard format categories (same as price analysis)\n",
    "    STANDARD_FORMATS = {\n",
    "        'Hardcover': 'Hardback',\n",
    "        'Hardback': 'Hardback',\n",
    "        'Paperback': 'Paperback',\n",
    "        'Kindle Edition': 'Digital',\n",
    "        'Kindle': 'Digital',\n",
    "        'eBook': 'Digital',\n",
    "        'Audio CD': 'Audio',\n",
    "        'Audiobook': 'Audio',\n",
    "        'Board Book': 'Board books',\n",
    "        'Pop-up Book': 'Novelty',\n",
    "        'Sound Book': 'Novelty',\n",
    "        'Touch and Feel': 'Novelty',\n",
    "        'Novelty Book': 'Novelty',\n",
    "        'Activity Book': 'Novelty',\n",
    "        'Spiral-bound': 'Other',\n",
    "        'Calendar': 'Other',\n",
    "        'Cards': 'Other',\n",
    "        'Map': 'Other',\n",
    "        'Library Binding': 'Hardback',\n",
    "        'Mass Market Paperback': 'Paperback'\n",
    "    }\n",
    "    \n",
    "    # Apply format grouping\n",
    "    df['format_grouped'] = df['standardized_format'].map(\n",
    "        lambda x: STANDARD_FORMATS.get(x, 'Other')\n",
    "    )\n",
    "    \n",
    "    # Calculate format distribution by category\n",
    "    format_dist = df.groupby(\n",
    "        ['processing_date', 'main_category', 'format_grouped']\n",
    "    ).agg({\n",
    "        'isbn13': 'count',\n",
    "        'price': ['mean', 'median'],\n",
    "        'rating': 'mean',\n",
    "        'review_count': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    format_dist.columns = [\n",
    "        f'{x[0]}_{x[1]}' if x[1] != '' else x[0]\n",
    "        for x in format_dist.columns\n",
    "    ]\n",
    "    \n",
    "    return format_dist.reset_index()\n",
    "\n",
    "def prepare_category_crossover(df):\n",
    "    \"\"\"\n",
    "    Analyze books appearing in multiple categories\n",
    "    Tracks category combinations and their frequency\n",
    "    \"\"\"\n",
    "    # Create pairs of categories where books appear in multiple categories\n",
    "    category_pairs = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        categories = [\n",
    "            row['main_category'],\n",
    "            row.get('category_1'),\n",
    "            row.get('category_2'),\n",
    "            row.get('category_3')\n",
    "        ]\n",
    "        # Remove None/NaN values\n",
    "        categories = [c for c in categories if pd.notna(c)]\n",
    "        categories = list(set(categories))  # Remove duplicates\n",
    "        \n",
    "        # Create pairs if book appears in multiple categories\n",
    "        if len(categories) > 1:\n",
    "            for i in range(len(categories)):\n",
    "                for j in range(i + 1, len(categories)):\n",
    "                    category_pairs.append({\n",
    "                        'processing_date': row['processing_date'],\n",
    "                        'category_1': categories[i],\n",
    "                        'category_2': categories[j],\n",
    "                        'isbn13': row['isbn13'],\n",
    "                        'title': row['title']\n",
    "                    })\n",
    "    \n",
    "    if category_pairs:\n",
    "        crossover_df = pd.DataFrame(category_pairs)\n",
    "        # Calculate frequency of category pairs\n",
    "        pair_stats = crossover_df.groupby(\n",
    "            ['processing_date', 'category_1', 'category_2']\n",
    "        ).agg({\n",
    "            'isbn13': 'count'  # Number of books in both categories\n",
    "        }).reset_index()\n",
    "        \n",
    "        return pair_stats\n",
    "    \n",
    "    return pd.DataFrame()  # Return empty DataFrame if no crossover\n",
    "\n",
    "def export_category_analysis(df):\n",
    "    \"\"\"\n",
    "    Main function to prepare and export all category analysis for PowerBI\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    output_dir = Path('../data/powerbi')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Prepare all datasets\n",
    "    main_category_stats = prepare_main_category_data(df)\n",
    "    subcategory_stats = prepare_subcategory_data(df)\n",
    "    format_distribution = prepare_category_format_analysis(df)\n",
    "    category_crossover = prepare_category_crossover(df)\n",
    "    \n",
    "    # Export to CSV with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d')\n",
    "    \n",
    "    # Export main datasets\n",
    "    main_category_stats.to_csv(\n",
    "        output_dir / f'main_category_analysis_{timestamp}.csv',\n",
    "        index=False\n",
    "    )\n",
    "    subcategory_stats.to_csv(\n",
    "        output_dir / f'subcategory_analysis_{timestamp}.csv',\n",
    "        index=False\n",
    "    )\n",
    "    format_distribution.to_csv(\n",
    "        output_dir / f'category_format_analysis_{timestamp}.csv',\n",
    "        index=False\n",
    "    )\n",
    "    category_crossover.to_csv(\n",
    "        output_dir / f'category_crossover_{timestamp}.csv',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    # Export a summary of what was processed\n",
    "    summary = pd.DataFrame({\n",
    "        'dataset': [\n",
    "            'main_category_stats', \n",
    "            'subcategory_stats',\n",
    "            'format_distribution',\n",
    "            'category_crossover'\n",
    "        ],\n",
    "        'record_count': [\n",
    "            len(main_category_stats),\n",
    "            len(subcategory_stats),\n",
    "            len(format_distribution),\n",
    "            len(category_crossover)\n",
    "        ],\n",
    "        'export_date': timestamp\n",
    "    })\n",
    "    \n",
    "    summary.to_csv(output_dir / f'category_export_summary_{timestamp}.csv', index=False)\n",
    "    \n",
    "    return {\n",
    "        'main_category_stats': main_category_stats,\n",
    "        'subcategory_stats': subcategory_stats,\n",
    "        'format_distribution': format_distribution,\n",
    "        'category_crossover': category_crossover,\n",
    "        'summary': summary\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the master dataset\n",
    "    df = pd.read_csv('../data/processed/master_bestsellers.csv')\n",
    "    \n",
    "    # Run the export\n",
    "    results = export_category_analysis(df)\n",
    "    \n",
    "    # Print summary of export\n",
    "    print(\"\\n=== Export Summary ===\")\n",
    "    print(results['summary'].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
